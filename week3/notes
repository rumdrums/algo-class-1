QuickSort!
. one of the 'greatest hits'
. superior to mergesort

Overview:
. input: given array of n numbers, unsorted
 -- assumption for now: no duplicates
. output: array in increasing order

Partitioning around a pivot
. partition the array around a pivot element
. rearrange so all elements on one side smaller, 
  all on other side larger
. ** note: doing this puts the pivot element in its proper place
. partitioning:
 -- 1) can be done quickly, in linear (O(n)) time with no extra memory used
 -- 2) reduces problem size
      -- just recursively sort after the partition

#########################
Algorithm -- array A, length n
. if n = 1: return
. p = ChoosePivot(A,n) -- not implemented
. partition A around p
. recursively sort 1st part
. recursively sort 2nd part
########################

Easy Approach
. Allocate a second array to serve as destination
 -- requires using O(n) extra memory
. iterate through first array
  -- for each item:
    -- if less than, push to beginning of new array
    -- if greater than, push to end of array

Hard "in-place" way (no extra memory)
. Assume for now: pivot = 1st element of array
. Single linear scan of input array
. all stuff we've already looked at will be sorted
. boundary to keep track of what we've looked at and what we haven't
 -- j
. of the stuff we've seen, where is the boundary between those
  greater than and those less than the pivot
 -- i
... So:
. subroutine:

# this does not fully sort array, it's just one 
# partition
func Partition(A, l, r) -- A is array, l is left-most index, r is right-most index
  p := A[l]
  i := l + 1
  for j=l+1; j < r; j++ :
    if A[j] < p:   ( if > p, do nothing)
      swap A[j] with A[i] (the left-most element that's BIGGER than p)
      increment i
 # the last thing you effectively do is put the pivot into its proper place
   -- how you do this depends on which side pivot is (ie whether to choose
     right-most of l or left-most of r

Proof by Induction
. Assertion P(n): quicksort correctly sorts every input array of length n
1) Base case: 
 -- assertion holds when P(1)

2) Inductive step:
 -- for every n >= 2, prove that if P(k) holds for all k<n, then P(n) holds as well

So, the proof:
. claim: P(n) holds for every n>=1
. base case: elements of 1 array already sorted, just return the array
. inductive step -- if P(k) holds where k<n, P(n) holds as well
. steps:
 -- partition
 -- take the left and right groups (those bigger and smaller than pivot after partitioning)
   -- k1 and k2 ( which are both < n)
   -- assert that P(k1) and P(k2)
 -- first recursive call: put all of elements < p in correct order
 -- second recursive call: put all elements > p in correct order
. QED ( I guess ? )

Runtime of Quicksort depends on quality of pivot choice
. worst case:
 -- if array is already sorted, and you always choose the first element,
    quicksort runs in quadratic time: (O(n^2))
. best case:
 -- if every recursive call chooses the median element of the subarray as its pivot,
    quicksort runs in O(nlogn) time

*** So how do we choose a good pivot?
. Random pivots -- every recursive call, 
  choose element within array of length k with equal probability 1/k
 -- randomization is often crucial in algorithm design
 -- goal is to be good __on average__
. If we always get a 25/75 split on recursive calls, good enough for O(nlogn) time

Probability Review
. linearity of expectation:
  -- the property that the expected value of the sum 
     of random variables is equal to the sum of their 
     individual expected values, regardless of whether
     they are independent.
. conditional probability
 -- Pr(x|y) -- probability of x given y
   == Pr(intersection of x and y) / Pr(y) -- intersection looks like upside down horseshoe)
. independence
 -- can be a very subtle concept and causes huge percentage of bugs
    when formulating algorithms
 -- safe to assume things are dependent unless you can prove they're not
 -- if A,B are independent, then E(A*B) = E(A) * E(B)

Proving Randomized Quicksort
. C(sigma): # of comparisons between 2 numbers made by quicksort
. prove that E(C) = O(nlogn)
. can't apply master method (unbalanced suproblems given randomnness)
. decomposition:
  -- take the random variables you care about
  -- break them into smaller random variables
  -- get the value of the random variables you
     care about using principle of Linearity of Expectation
  -- *** E(C) = sum of probabilities that each z_i,z_j pair gets compared
  -- x_ij is the number of times a given pair (z_i and z_j) gets compared

. claim: Pr(zi, zj get compared) = 2 / (j - i + 1 )
 -- (j - i + 1) -- is just the number of possible choices for the pivot in a recursive call
 -- since all elements are equally likely to be chosen as pivot, the likelihood that either
    i or j becomes the pivot is just 1/(j-i+1) + 1/(j-i+1) = 2/(j-i+1)
 -- so E(C) is just the sum of the probabilities of each pair of points
 -- 2 * Sigma_i...n-1 ( Sigma_j=i+1...n ( 1/(j-i+1 )))
 -- simplifying this a bit...
   -- 2 * n (instead of n - 1) * Sigma_k=2...n ( 1/k)
     -- since the largest in denominator will be 2 (ie when j=2 and i=1 (since 2-1+2 == 2),
        you can simplify to just looking at 1/k for all k in n
     -- when you sum this, it is a logarithmic function of n
 -- so, 2 * n (log n) == O(nlogn)

